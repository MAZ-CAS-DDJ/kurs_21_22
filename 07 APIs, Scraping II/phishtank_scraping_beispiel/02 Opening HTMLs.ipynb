{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as n\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making list of htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(\"html/\")\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting list into number of chunks. I need this for the tags in the html code\n",
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiting each html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultlst = []\n",
    "errors = []\n",
    "\n",
    "for elem in tqdm(lst):\n",
    "    #print(elem)\n",
    "    file = open('html/'+elem, 'r')\n",
    "    text = file.read()\n",
    "    html = BeautifulSoup(text, 'html.parser')\n",
    "    html = html.find_all('td')\n",
    "    taglist = list(chunks(html, 5))\n",
    "    for tags in taglist:\n",
    "        try:\n",
    "            \n",
    "            mini_dict = {'ID':tags[0].text,\n",
    "                     'URL':tags[1].text.split('added')[0],\n",
    "                     'Date':tags[1].text.split('added')[1],\n",
    "                     'Valid Phish':tags[3].text}\n",
    "            resultlst.append(mini_dict)\n",
    "        except:\n",
    "            errors.append(elem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishlist = pd.DataFrame(resultlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishlist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving off the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishlist.to_csv('d/goverCERTphishes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
